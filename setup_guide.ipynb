{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Vision Transformer in Federated Learning - Setup Guide\n",
        "\n",
        "This notebook will guide you through the process of setting up and running the ViT-FL model based on the paper [\"Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning\"](https://arxiv.org/abs/2106.06047).\n",
        "\n",
        "We'll go through the following steps:\n",
        "1. Installing Required Dependencies\n",
        "2. Downloading and Preparing the Dataset\n",
        "3. Setting up Pre-trained Models\n",
        "4. Running the Model Training\n",
        "\n",
        "Let's get started!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "requirements.txt found. Installing dependencies...\n",
            "Requirement already satisfied: torch in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.7.0)\n",
            "Requirement already satisfied: numpy in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (2.2.6)\n",
            "Requirement already satisfied: tqdm in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (2.19.0)\n",
            "Requirement already satisfied: ml-collections in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: timm in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (1.0.15)\n",
            "Requirement already satisfied: pandas in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (2.2.3)\n",
            "Requirement already satisfied: scikit-image in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (0.25.2)\n",
            "Requirement already satisfied: filelock in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (4.14.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.5)\n",
            "Requirement already satisfied: jinja2 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (2025.5.1)\n",
            "Requirement already satisfied: setuptools in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (80.9.0)\n",
            "Requirement already satisfied: colorama in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from tqdm->-r requirements.txt (line 3)) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 4)) (1.72.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 4)) (3.8)\n",
            "Requirement already satisfied: packaging in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 4)) (6.31.1)\n",
            "Requirement already satisfied: six>1.9 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 4)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 4)) (3.1.3)\n",
            "Requirement already satisfied: PyYAML in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from ml-collections->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: torchvision in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from timm->-r requirements.txt (line 6)) (0.22.0)\n",
            "Requirement already satisfied: huggingface_hub in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from timm->-r requirements.txt (line 6)) (0.32.4)\n",
            "Requirement already satisfied: safetensors in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from timm->-r requirements.txt (line 6)) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from scikit-image->-r requirements.txt (line 8)) (1.15.3)\n",
            "Requirement already satisfied: pillow>=10.1 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from scikit-image->-r requirements.txt (line 8)) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from scikit-image->-r requirements.txt (line 8)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from scikit-image->-r requirements.txt (line 8)) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from scikit-image->-r requirements.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: requests in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from huggingface_hub->timm->-r requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\lucas\\5 - cadeiras\\1 periodo - mestrado\\visao computacional\\vit-fl-fedbabu\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 6)) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "\n",
        "# # Check if requirements.txt exists\n",
        "# if os.path.exists('requirements.txt'):\n",
        "#     print(\"requirements.txt found. Installing dependencies...\")\n",
        "#     %pip install -r requirements.txt\n",
        "# else:\n",
        "#     print(\"requirements.txt not found. Please make sure you're in the correct directory.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Downloading and Preparing the Dataset\n",
        "\n",
        "For this guide, we'll use the CIFAR-10 dataset. You need to:\n",
        "\n",
        "1. Download the data partitions from [Google Drive](https://drive.google.com/drive/folders/1ZErR7RMSVImkzYzz0hLl25f9agJwp0Zx?usp=sharing)\n",
        "2. Place the downloaded `cifar10.npy` file in the `data` subdirectory\n",
        "\n",
        "Let's create the data directory if it doesn't exist and check for the dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CIFAR-10 dataset found!\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "\n",
        "# # Create data directory if it doesn't exist\n",
        "# if not os.path.exists('data'):\n",
        "#     os.makedirs('data')\n",
        "#     print(\"Created 'data' directory\")\n",
        "\n",
        "# # Check if the dataset file exists\n",
        "# if os.path.exists('data/cifar10.npy'):\n",
        "#     print(\"CIFAR-10 dataset found!\")\n",
        "# else:\n",
        "#     print(\"Please download cifar10.npy from the Google Drive link and place it in the 'data' directory\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Setting up Pre-trained Models\n",
        "\n",
        "For ViTs, we need to modify the pre-trained model loading links in the timm library. The models we'll be using are pre-trained on ImageNet1K. Here are the steps:\n",
        "\n",
        "1. Locate the `vision_transformer.py` file in your timm installation\n",
        "2. Modify the `default_cfgs` dictionary with the correct URLs for the pre-trained models\n",
        "\n",
        "For this example, we'll use ViT-small. The URL should be:\n",
        "```python\n",
        "'vit_small_patch16_224': _cfg(\n",
        "    url='https://storage.googleapis.com/vit_models/augreg/S_16-i1k-300ep-lr_0.001-aug_medium2-wd_0.1-do_0.0-sd_0.0.npz')\n",
        "```\n",
        "\n",
        "Let's check the timm installation and locate the file:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found vision_transformer.py at: d:\\lucas\\5 - cadeiras\\1 periodo - Mestrado\\Visao computacional\\ViT-FL-FedBABU\\venv\\lib\\site-packages\\timm\\models\\vision_transformer.py\n",
            "\n",
            "Please modify the default_cfgs dictionary in this file with the correct URL for ViT-small\n"
          ]
        }
      ],
      "source": [
        "import timm\n",
        "import os\n",
        "\n",
        "# Get timm installation directory\n",
        "timm_dir = os.path.dirname(timm.__file__)\n",
        "vit_file = os.path.join(timm_dir, 'models', 'vision_transformer.py')\n",
        "\n",
        "if os.path.exists(vit_file):\n",
        "    print(f\"Found vision_transformer.py at: {vit_file}\")\n",
        "    print(\"\\nPlease modify the default_cfgs dictionary in this file with the correct URL for ViT-small\")\n",
        "else:\n",
        "    print(\"Could not find vision_transformer.py. Please check your timm installation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Running the Model Training\n",
        "\n",
        "Now that we have everything set up, we can run the model training. We'll use the ViT-CWT implementation with the following configuration:\n",
        "- Dataset: CIFAR-10\n",
        "- Split type: split_2\n",
        "- Network: ViT-small\n",
        "- Local epochs: 1\n",
        "- Communication rounds: 100\n",
        "\n",
        "Here's the command to run the training:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing compatible version of timm...\n",
            "\n",
            "Installed timm version: 0.3.2\n",
            "Successfully imported _pil_interp from timm.data.transforms!\n"
          ]
        }
      ],
      "source": [
        "# Uninstall current timm version and install the compatible version\n",
        "print(\"Installing compatible version of timm...\")\n",
        "# %pip uninstall -y timm\n",
        "# %pip install timm==0.5.4  # This version should have _pil_interp\n",
        "\n",
        "# Verify timm version\n",
        "import timm\n",
        "print(f\"\\nInstalled timm version: {timm.__version__}\")\n",
        "\n",
        "# Check if _pil_interp is available\n",
        "try:\n",
        "    from timm.data.transforms import _pil_interp\n",
        "    print(\"Successfully imported _pil_interp from timm.data.transforms!\")\n",
        "except ImportError as e:\n",
        "    print(f\"Error importing _pil_interp: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running training command with explicit Python path:\n",
            "\"d:\\lucas\\5 - cadeiras\\1 periodo - Mestrado\\Visao computacional\\ViT-FL-FedBABU\\venv\\Scripts\\python.exe\" train_CWT.py --FL_platform ViT-CWT --net_name ViT-tiny --dataset cifar10 --E_epoch 1 --max_communication_rounds 100 --split_type split_2 --save_model_flag\n",
            "\n",
            "Executing the command...\n",
            "We use ViT tiny\n",
            "sgd\n",
            "================ FL train of ViT-CWT with total model parameters: 5.5M  ================\n",
            "++++++++++++++++ Other Train related parameters ++++++++++++++++\n",
            "E_epoch: 1\n",
            "FL_platform: ViT-CWT\n",
            "Pretrained: True\n",
            "batch_size: 32\n",
            "cfg: configs/swin_tiny_patch4_window7_224.yaml\n",
            "data_path: ./data/\n",
            "dataset: cifar10\n",
            "decay_type: cosine\n",
            "device: cuda:0\n",
            "gpu_ids: 0\n",
            "grad_clip: True\n",
            "img_size: 224\n",
            "learning_rate: 0.003\n",
            "max_communication_rounds: 100\n",
            "max_grad_norm: 1.0\n",
            "name: ViT-tiny_split_2_lr_0.003_Pretrained_True_optimizer_sgd_WUP_500_Round_100_Eepochs_1_Seed_42\n",
            "net_name: ViT-tiny\n",
            "num_classes: 10\n",
            "num_workers: 4\n",
            "optimizer_type: sgd\n",
            "output_dir: output\\ViT-CWT\\cifar10\\ViT-tiny_split_2_lr_0.003_Pretrained_True_optimizer_sgd_WUP_500_Round_100_Eepochs_1_Seed_42\n",
            "pretrained_dir: checkpoint/swin_tiny_patch4_window7_224.pth\n",
            "save_model_flag: True\n",
            "seed: 42\n",
            "split_type: split_2\n",
            "step_size: 30\n",
            "warmup_steps: 500\n",
            "weight_decay: 0\n",
            "++++++++++++++++  End of show parameters ++++++++++++++++\n",
            "=============== Running training ===============\n",
            "Train the client train_1 of communication round 0\n",
            "Client: train_1 inner epoch: 0 step: 9 (282), round: 0 (100) loss: 5.42 lr:  0.000060\n",
            "Client: train_1 inner epoch: 0 step: 19 (282), round: 0 (100) loss: 5.20 lr:  0.000120\n",
            "Client: train_1 inner epoch: 0 step: 29 (282), round: 0 (100) loss: 4.90 lr:  0.000180\n",
            "Client: train_1 inner epoch: 0 step: 39 (282), round: 0 (100) loss: 4.14 lr:  0.000240\n",
            "Client: train_1 inner epoch: 0 step: 49 (282), round: 0 (100) loss: 3.67 lr:  0.000300\n",
            "Client: train_1 inner epoch: 0 step: 59 (282), round: 0 (100) loss: 2.68 lr:  0.000360\n",
            "Client: train_1 inner epoch: 0 step: 69 (282), round: 0 (100) loss: 2.82 lr:  0.000420\n",
            "Client: train_1 inner epoch: 0 step: 79 (282), round: 0 (100) loss: 1.87 lr:  0.000480\n",
            "Client: train_1 inner epoch: 0 step: 89 (282), round: 0 (100) loss: 1.24 lr:  0.000540\n",
            "Client: train_1 inner epoch: 0 step: 99 (282), round: 0 (100) loss: 1.29 lr:  0.000600\n",
            "Client: train_1 inner epoch: 0 step: 109 (282), round: 0 (100) loss: 1.12 lr:  0.000660\n",
            "Client: train_1 inner epoch: 0 step: 119 (282), round: 0 (100) loss: 0.85 lr:  0.000720\n"
          ]
        }
      ],
      "source": [
        "# Try running the training command again with the compatible timm version\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "python_executable = sys.executable\n",
        "cmd = f'\"{python_executable}\" train_CWT.py --FL_platform ViT-CWT --net_name ViT-tiny --dataset cifar10 --E_epoch 1 --max_communication_rounds 100 --split_type split_2 --save_model_flag'\n",
        "\n",
        "print(\"Running training command with explicit Python path:\")\n",
        "print(cmd)\n",
        "print(\"\\nExecuting the command...\")\n",
        "\n",
        "try:\n",
        "    # Run the command\n",
        "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, shell=True)\n",
        "    \n",
        "    # Print output in real-time\n",
        "    while True:\n",
        "        output = process.stdout.readline()\n",
        "        if output == '' and process.poll() is not None:\n",
        "            break\n",
        "        if output:\n",
        "            print(output.strip())\n",
        "            \n",
        "    # Print any errors\n",
        "    stderr = process.stderr.read()\n",
        "    if stderr:\n",
        "        print(\"\\nErrors:\")\n",
        "        print(stderr)\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python executable: d:\\lucas\\5 - cadeiras\\1 periodo - Mestrado\\Visao computacional\\ViT-FL-FedBABU\\.venv\\Scripts\\python.exe\n",
            "\n",
            "Checking if numpy is installed correctly...\n",
            "Numpy is installed! Version: 2.2.6\n"
          ]
        }
      ],
      "source": [
        "# Let's verify our Python environment and numpy installation\n",
        "import sys\n",
        "print(\"Python executable:\", sys.executable)\n",
        "print(\"\\nChecking if numpy is installed correctly...\")\n",
        "try:\n",
        "    import numpy\n",
        "    print(f\"Numpy is installed! Version: {numpy.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"Numpy is not installed in the current environment. Let's install it...\")\n",
        "    %pip install numpy --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running training command with explicit Python path:\n",
            "\"d:\\lucas\\5 - cadeiras\\1 periodo - Mestrado\\Visao computacional\\ViT-FL-FedBABU\\.venv\\Scripts\\python.exe\" train_CWT.py --FL_platform ViT-CWT --net_name ViT-small --dataset cifar10 --E_epoch 1 --max_communication_rounds 100 --split_type split_2 --save_model_flag\n",
            "\n",
            "Executing the command...\n",
            "\n",
            "Errors:\n",
            "Traceback (most recent call last):\n",
            "  File \u001b[35m\"d:\\lucas\\5 - cadeiras\\1 periodo - Mestrado\\Visao computacional\\ViT-FL-FedBABU\\train_CWT.py\"\u001b[0m, line \u001b[35m16\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    from utils.data_utils import DatasetFLViT, create_dataset_and_evalmetrix\n",
            "  File \u001b[35m\"d:\\lucas\\5 - cadeiras\\1 periodo - Mestrado\\Visao computacional\\ViT-FL-FedBABU\\utils\\data_utils.py\"\u001b[0m, line \u001b[35m10\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    from timm.data.transforms import _pil_interp\n",
            "\u001b[1;35mImportError\u001b[0m: \u001b[35mcannot import name '_pil_interp' from 'timm.data.transforms' (d:\\lucas\\5 - cadeiras\\1 periodo - Mestrado\\Visao computacional\\ViT-FL-FedBABU\\.venv\\Lib\\site-packages\\timm\\data\\transforms.py)\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's modify the training command to use the same Python interpreter as our notebook\n",
        "python_executable = sys.executable\n",
        "cmd = f'\"{python_executable}\" train_CWT.py --FL_platform ViT-CWT --net_name ViT-small --dataset cifar10 --E_epoch 1 --max_communication_rounds 100 --split_type split_2 --save_model_flag'\n",
        "\n",
        "print(\"Running training command with explicit Python path:\")\n",
        "print(cmd)\n",
        "print(\"\\nExecuting the command...\")\n",
        "\n",
        "try:\n",
        "    # Run the command\n",
        "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, shell=True)\n",
        "    \n",
        "    # Print output in real-time\n",
        "    while True:\n",
        "        output = process.stdout.readline()\n",
        "        if output == '' and process.poll() is not None:\n",
        "            break\n",
        "        if output:\n",
        "            print(output.strip())\n",
        "            \n",
        "    # Print any errors\n",
        "    stderr = process.stderr.read()\n",
        "    if stderr:\n",
        "        print(\"\\nErrors:\")\n",
        "        print(stderr)\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running training command:\n",
            "python3 train_CWT.py --FL_platform ViT-CWT --net_name ViT-small --dataset cifar10 --E_epoch 1 --max_communication_rounds 100 --split_type split_2 --save_model_flag\n",
            "\n",
            "Executing the command...\n",
            "\n",
            "Errors:\n",
            "Traceback (most recent call last):\n",
            "  File \u001b[35m\"d:\\lucas\\5 - cadeiras\\1 periodo - Mestrado\\Visao computacional\\ViT-FL-FedBABU\\train_CWT.py\"\u001b[0m, line \u001b[35m7\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    import numpy as np\n",
            "\u001b[1;35mModuleNotFoundError\u001b[0m: \u001b[35mNo module named 'numpy'\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "# Command to run the training\n",
        "cmd = \"python train_CWT.py --FL_platform ViT-CWT --net_name ViT-small --dataset cifar10 --E_epoch 1 --max_communication_rounds 5 --split_type split_2 --save_model_flag\"\n",
        "\n",
        "print(\"Running training command:\")\n",
        "print(cmd)\n",
        "print(\"\\nExecuting the command...\")\n",
        "\n",
        "try:\n",
        "    # Run the command\n",
        "    process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    \n",
        "    # Print output in real-time\n",
        "    while True:\n",
        "        output = process.stdout.readline()\n",
        "        if output == '' and process.poll() is not None:\n",
        "            break\n",
        "        if output:\n",
        "            print(output.strip())\n",
        "            \n",
        "    # Print any errors\n",
        "    stderr = process.stderr.read()\n",
        "    if stderr:\n",
        "        print(\"\\nErrors:\")\n",
        "        print(stderr)\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Notes and Troubleshooting\n",
        "\n",
        "1. All checkpoints, results, and log files will be saved to the `output_dir` folder\n",
        "2. The final performance will be saved in `log_file.txt`\n",
        "3. If you encounter any errors:\n",
        "   - Make sure all dependencies are properly installed\n",
        "   - Verify that the CIFAR-10 dataset is in the correct location\n",
        "   - Check that the pre-trained model URLs are properly configured in the timm library\n",
        "   - Ensure you have sufficient disk space for model checkpoints and results\n",
        "\n",
        "You can also try the FedAVG implementation using a similar command:\n",
        "```python\n",
        "python train_FedAVG.py --FL_platform ViT-FedAVG --net_name ViT-small --dataset cifar10 --E_epoch 1 --max_communication_rounds 100 --num_local_clients -1 --split_type split_2 --save_model_flag\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
